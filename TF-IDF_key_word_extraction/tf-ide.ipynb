{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "import scispacy\n",
    "import spacy\n",
    "import en_core_sci_sm   #需要先 pip install <Model URL> 对应的包的超链接\n",
    "from spacy import displacy\n",
    "from scispacy.abbreviation import AbbreviationDetector\n",
    "from scispacy.umls_linking import UmlsEntityLinker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 我们就用spacy做词语检索和画图\n",
    "2. 我们用LDA进行主题关键词生成\n",
    "3. 我们用spacy里的word2vec进行词语匹配，然后再检索(有一个similarity)\n",
    "4. 我们用每个里面的词语的word2vec制造的词向量，然后用一个模型进行训练，预测其死亡还是没死亡(5w多个患者)\n",
    "\n",
    "5. bert embedding的参考 https://github.com/kexinhuang12345/clinicalBERT/blob/master/modeling_readmission.py\n",
    "    \n",
    "6.https://github.com/cchantra/nlp_tourism  全面的\n",
    "    \n",
    "    https://explosion.ai/blog/spacy-transformers\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本例中参考的链接:\n",
    "#https://github.com/kavgan/nlp-in-practice/blob/master/tf-idf/Keyword%20Extraction%20with%20TF-IDF%20and%20SKlearn.ipynb\n",
    "\n",
    "详解tf-IDF: https://drive.google.com/file/d/1EhucFINkDNEDCsrmyxHr_UWQcdYRmI4e/view\n",
    "\n",
    "tf-ide这类是count-based不是深度学习类的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_note=pd.read_csv('NOTEEVENTS.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import time\n",
    "\n",
    "\n",
    "def remove_punct(text):\n",
    "    table=str.maketrans('','',string.punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "    \n",
    "df_note.TEXT=df_note.TEXT.apply(remove_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_note['len_count']=df_note.TEXT.apply(lambda x: len(x))\n",
    "\n",
    "import re\n",
    "\n",
    "def pre_process(text):\n",
    "    \n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"</?.*?>\",\" <> \",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_note['TEXT'] = df_note['TEXT'].apply(lambda x:pre_process(x))\n",
    "\n",
    "#show the first 'text'\n",
    "\n",
    "\n",
    "df_note['len_count']=df_note.TEXT.apply(lambda x: len(x))\n",
    "df_note=df_note[df_note['len_count']>50]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#就用这个ipynb作为指导\n",
    "#https://github.com/kavgan/nlp-in-practice/blob/master/tf-idf/Keyword%20Extraction%20with%20TF-IDF%20and%20SKlearn.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after we clean the data, we have  (2072810, 12)\n"
     ]
    }
   ],
   "source": [
    "print('after we clean the data, we have ', df_note.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop word cost:  1773.0621089935303  s\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "  \n",
    "stop_words = set(stopwords.words('english')) \n",
    "  \n",
    "\n",
    "def get_stop_word(text, stop_list): #clear useless stop words\n",
    "    result=[]\n",
    "    text=word_tokenize(text)\n",
    "    for i in text:\n",
    "        if i not in stop_list and len(i)>2:\n",
    "            result.append(i)\n",
    "    return ' '.join(result)\n",
    "\n",
    "\n",
    "begin=time.time()\n",
    "df_note['TEXT']=df_note['TEXT'].apply(lambda x: get_stop_word(x,stop_words))\n",
    "print('stop word cost: ',time.time()-begin,' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(df_note,'cleaned_note.csv') #存储清洗后的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "F:\\anaconda\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df_clean=pd.read_csv('cleaned_note.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CHARTDATE</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>STORETIME</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CGID</th>\n",
       "      <th>ISERROR</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>len_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>22532</td>\n",
       "      <td>167853.0</td>\n",
       "      <td>2151-08-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date Discharge Date Service ADDENDUM...</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>13702</td>\n",
       "      <td>107527.0</td>\n",
       "      <td>2118-06-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date Discharge Date Date Birth Sex S...</td>\n",
       "      <td>11083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>176</td>\n",
       "      <td>13702</td>\n",
       "      <td>167118.0</td>\n",
       "      <td>2119-05-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date Discharge Date Service CARDIOTH...</td>\n",
       "      <td>7970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>177</td>\n",
       "      <td>13702</td>\n",
       "      <td>196489.0</td>\n",
       "      <td>2124-08-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date Discharge Date Service MEDICINE...</td>\n",
       "      <td>14405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>178</td>\n",
       "      <td>26880</td>\n",
       "      <td>135453.0</td>\n",
       "      <td>2162-03-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date Discharge Date Date Birth Sex S...</td>\n",
       "      <td>12930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2083175</td>\n",
       "      <td>2070657</td>\n",
       "      <td>31097</td>\n",
       "      <td>115637.0</td>\n",
       "      <td>2132-01-21</td>\n",
       "      <td>2132-01-21 03:27:00</td>\n",
       "      <td>2132-01-21 03:38:00</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>Report</td>\n",
       "      <td>17581.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NPN Infant remains sats mild ICRSCR clear equa...</td>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2083176</td>\n",
       "      <td>2070658</td>\n",
       "      <td>31097</td>\n",
       "      <td>115637.0</td>\n",
       "      <td>2132-01-21</td>\n",
       "      <td>2132-01-21 09:50:00</td>\n",
       "      <td>2132-01-21 09:53:00</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>Report</td>\n",
       "      <td>19211.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neonatology DOL CGA weeks CVR Continues sats o...</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2083177</td>\n",
       "      <td>2070659</td>\n",
       "      <td>31097</td>\n",
       "      <td>115637.0</td>\n",
       "      <td>2132-01-21</td>\n",
       "      <td>2132-01-21 16:42:00</td>\n",
       "      <td>2132-01-21 16:44:00</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>Report</td>\n",
       "      <td>20104.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Family Meeting Note Family meeting held Name D...</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2083178</td>\n",
       "      <td>2070660</td>\n",
       "      <td>31097</td>\n",
       "      <td>115637.0</td>\n",
       "      <td>2132-01-21</td>\n",
       "      <td>2132-01-21 18:05:00</td>\n",
       "      <td>2132-01-21 18:16:00</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>Report</td>\n",
       "      <td>16023.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NPN Resp Known lastname remains sat spells des...</td>\n",
       "      <td>1688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2083179</td>\n",
       "      <td>2070661</td>\n",
       "      <td>31097</td>\n",
       "      <td>115637.0</td>\n",
       "      <td>2132-01-21</td>\n",
       "      <td>2132-01-21 18:05:00</td>\n",
       "      <td>2132-01-21 18:31:00</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>Report</td>\n",
       "      <td>16023.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NPN Nursing Addendum Known lastname changed today</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2072810 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE            CHARTTIME  \\\n",
       "0            174       22532  167853.0  2151-08-04                  NaN   \n",
       "1            175       13702  107527.0  2118-06-14                  NaN   \n",
       "2            176       13702  167118.0  2119-05-25                  NaN   \n",
       "3            177       13702  196489.0  2124-08-18                  NaN   \n",
       "4            178       26880  135453.0  2162-03-25                  NaN   \n",
       "...          ...         ...       ...         ...                  ...   \n",
       "2083175  2070657       31097  115637.0  2132-01-21  2132-01-21 03:27:00   \n",
       "2083176  2070658       31097  115637.0  2132-01-21  2132-01-21 09:50:00   \n",
       "2083177  2070659       31097  115637.0  2132-01-21  2132-01-21 16:42:00   \n",
       "2083178  2070660       31097  115637.0  2132-01-21  2132-01-21 18:05:00   \n",
       "2083179  2070661       31097  115637.0  2132-01-21  2132-01-21 18:05:00   \n",
       "\n",
       "                   STORETIME           CATEGORY DESCRIPTION     CGID  ISERROR  \\\n",
       "0                        NaN  Discharge summary      Report      NaN      NaN   \n",
       "1                        NaN  Discharge summary      Report      NaN      NaN   \n",
       "2                        NaN  Discharge summary      Report      NaN      NaN   \n",
       "3                        NaN  Discharge summary      Report      NaN      NaN   \n",
       "4                        NaN  Discharge summary      Report      NaN      NaN   \n",
       "...                      ...                ...         ...      ...      ...   \n",
       "2083175  2132-01-21 03:38:00      Nursing/other      Report  17581.0      NaN   \n",
       "2083176  2132-01-21 09:53:00      Nursing/other      Report  19211.0      NaN   \n",
       "2083177  2132-01-21 16:44:00      Nursing/other      Report  20104.0      NaN   \n",
       "2083178  2132-01-21 18:16:00      Nursing/other      Report  16023.0      NaN   \n",
       "2083179  2132-01-21 18:31:00      Nursing/other      Report  16023.0      NaN   \n",
       "\n",
       "                                                      TEXT  len_count  \n",
       "0        Admission Date Discharge Date Service ADDENDUM...        660  \n",
       "1        Admission Date Discharge Date Date Birth Sex S...      11083  \n",
       "2        Admission Date Discharge Date Service CARDIOTH...       7970  \n",
       "3        Admission Date Discharge Date Service MEDICINE...      14405  \n",
       "4        Admission Date Discharge Date Date Birth Sex S...      12930  \n",
       "...                                                    ...        ...  \n",
       "2083175  NPN Infant remains sats mild ICRSCR clear equa...        742  \n",
       "2083176  Neonatology DOL CGA weeks CVR Continues sats o...        513  \n",
       "2083177  Family Meeting Note Family meeting held Name D...        446  \n",
       "2083178  NPN Resp Known lastname remains sat spells des...       1688  \n",
       "2083179  NPN Nursing Addendum Known lastname changed today         67  \n",
       "\n",
       "[2072810 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorization :  237.86075806617737  s\n"
     ]
    }
   ],
   "source": [
    "#【调参可以从这里调】\n",
    "\n",
    "from nltk.corpus import stopwords #废话word，比如I ，are you\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "begin=time.time()\n",
    "cv2=CountVectorizer(max_df=0.95,stop_words=stop_words,max_features=1000) #调参\n",
    "docs=df_clean['TEXT'][0:1750000].tolist()\n",
    "cv_result=cv2.fit_transform(docs)\n",
    "\n",
    "print('vectorization : ',time.time()-begin,' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(cv_result)\n",
    "\n",
    "\n",
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "\n",
    "    for idx, score in sorted_items:\n",
    "        fname = feature_names[idx]\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names=cv2.get_feature_names()\n",
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female 0.62\n",
      "normal 0.316\n",
      "hrs 0.238\n",
      "due 0.192\n",
      "soft 0.167\n",
      "sepsis 0.13\n",
      "start 0.126\n",
      "aware 0.125\n",
      "diet 0.124\n",
      "service 0.124\n",
      "patent 0.123\n",
      "management 0.122\n",
      "evaluation 0.121\n",
      "tachycardia 0.121\n",
      "check 0.12\n",
      "infection 0.12\n",
      "sat 0.117\n",
      "location 0.116\n",
      "pulses 0.115\n",
      "fever 0.114\n"
     ]
    }
   ],
   "source": [
    "feature_names=cv2.get_feature_names()\n",
    "\n",
    "# get the document that we want to extract keywords from\n",
    "\n",
    "#测试一个\n",
    "doc=df_clean.TEXT[2050000]\n",
    "\n",
    "#generate tf-idf for the given document\n",
    "tf_idf_vector=tfidf_transformer.transform(cv2.transform([doc]))\n",
    "\n",
    "#sort the tf-idf vectors by descending order of scores\n",
    "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "#extract only the top n; n here is 10\n",
    "keywords=extract_topn_from_vector(feature_names,sorted_items,20) #打印这个doc的主题\n",
    "\n",
    "\n",
    "for k in keywords:\n",
    "    print(k,keywords[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
